# Q3. What are some common techniques used in Embedded feature selection methods?

# Answer - 

# L1 Regularization (Lasso):
# L1 regularization adds a penalty term to the model's loss function based on the absolute values of the feature coefficients. 
# This encourages many feature coefficients to become exactly zero, effectively performing feature selection.

# Tree-Based Methods:
# Decision tree-based algorithms like Random Forest and Gradient Boosting Machines (GBM) naturally perform feature selection during training. 
# They assess the importance 

# Elastic Net Regularization:
# Elastic Net combines both L1 (Lasso) and L2 (Ridge) regularization penalties. 
# It can be used to simultaneously perform feature selection and feature weighting.